{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pendientes\n",
        "# Formatear nombres de las columnas para eliminar espacios\n",
        "# Hacer iteraciones para aplicar las funciones sobre múltiples datasets\n",
        "# Simplificar la función de lectura y formateo de columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XcO1PRNrAi5Q"
      },
      "outputs": [],
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4owhwnltBD22"
      },
      "outputs": [],
      "source": [
        "# Definir la ruta de los datos\n",
        "\n",
        "# Sitio norte\n",
        "fp_north_1 = '../../data/raw/soil-sensors/z6-25818/z6-25818(z6-25818)-Configuration 3-1756238685.7139447.csv'\n",
        "fp_north_2 = '../../data/raw/soil-sensors/z6-25818/z6-25818(z6-25818)-Configuration 4-1756238685.7139447.csv'\n",
        "\n",
        "# Sitio sur\n",
        "fp_south_1 = '../../data/raw\\soil-sensors/z6-26092/z6-26092(z6-26092)-Configuration 3-1756238687.030961.csv'\n",
        "fp_south_2 = '../../data/raw\\soil-sensors/z6-26092/z6-26092(z6-26092)-Configuration 4-1756238687.030961.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TYPOZs8pAkyv"
      },
      "outputs": [],
      "source": [
        "# Asignar la profundidad de cada instrumento a los puertos del datalogger\n",
        "\n",
        "# Sitio norte\n",
        "port_mapping_north = {\n",
        "    \"Port1\": \"TEROS12 -48cm\",\n",
        "    \"Port2\": \"TEROS12 -30cm\",\n",
        "    \"Port3\": \"TEROS12 -15cm\",\n",
        "    \"Port4\": \"TEROS21 -35cm\",\n",
        "    \"Port5\": \"TEROS21 -25cm\",\n",
        "}\n",
        "\n",
        "# Sitio sur\n",
        "port_mapping_south = {\n",
        "    \"Port1\": \"TEROS12 -65cm\",\n",
        "    \"Port2\": \"TEROS12 -45cm\",\n",
        "    \"Port3\": \"TEROS12 -18cm\",\n",
        "    \"Port4\": \"TEROS21 -55cm\",\n",
        "    \"Port5\": \"TEROS21 -31cm\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OCwBUCUuArOf"
      },
      "outputs": [],
      "source": [
        "# Funcion para leer los datos, renombrar los encabezados de las tablas\n",
        "# y formatear los datos al tipo correcto (numerico, fecha)\n",
        "\n",
        "def read_and_convert_data(filepath, port_mapping):\n",
        "\n",
        "    # Leer el archivo CSV\n",
        "    df = pd.read_csv(filepath, header=None, low_memory=False)\n",
        "\n",
        "    # Crear una lista vacia para las nuevas columnas\n",
        "    new_columns = []\n",
        "\n",
        "    # Iterar usando el indice de cada columna del df\n",
        "    for i in range(df.shape[1]):\n",
        "        # Extraer el nombre del puerto (ej. 'Port1') de la primera fila\n",
        "        port = str(df.iloc[0, i])\n",
        "        # Extraer la medida y unidad (ej. 'm3/m3 Water Content') de la tercera fila\n",
        "        measurement = str(df.iloc[2, i])\n",
        "\n",
        "        # Usar el mapeo si el puerto existe; de lo contrario, usar el nombre original del puerto\n",
        "        descriptive_name = port_mapping.get(port, port)\n",
        "\n",
        "        # La primera columna es 'Timestamps', por lo que se deja ese nombre\n",
        "        if i == 0:\n",
        "            final_name = measurement\n",
        "        else:\n",
        "            # Crear el nombre final de la columna combinando el nombre descriptivo y la medida\n",
        "            final_name = f\"{descriptive_name}{measurement}\"\n",
        "            \n",
        "        new_columns.append(final_name)\n",
        "\n",
        "    # Asignar la nueva lista de nombres de columna al df\n",
        "    df.columns = new_columns\n",
        "\n",
        "    # Eliminar las 3 primeras filas del df\n",
        "    df = df.iloc[3:].reset_index(drop=True)\n",
        "\n",
        "    # Convertir la columna de timestamps a datetime\n",
        "    df['Timestamps'] = pd.to_datetime(df['Timestamps'])\n",
        "\n",
        "    # Convertir todas las demás columnas a tipos numericos.\n",
        "    for col in df.columns:\n",
        "        if col != 'Timestamps':\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Establecer la columna 'Timestamps' como indice\n",
        "    df = df.set_index(\"Timestamps\")\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C1W4J_p_BkxV"
      },
      "outputs": [],
      "source": [
        "# Ejecutar la funcion de lectura y conversión de tipos de datos\n",
        "\n",
        "# Sitio norte\n",
        "north_soil_data_1 = read_and_convert_data(fp_north_1, port_mapping_north)\n",
        "north_soil_data_2 = read_and_convert_data(fp_north_2, port_mapping_north)\n",
        "\n",
        "# Sitio sur\n",
        "south_soil_data_1 = read_and_convert_data(fp_south_1, port_mapping_south)\n",
        "south_soil_data_2 = read_and_convert_data(fp_south_2, port_mapping_south)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_1l3hW4hJdLr"
      },
      "outputs": [],
      "source": [
        "# Unir los df de cada sitio en uno solo, y descartar las columnas no compartidas\n",
        "north_soil_data = pd.concat([north_soil_data_1, north_soil_data_2], join=\"inner\")\n",
        "south_soil_data = pd.concat([south_soil_data_1, south_soil_data_2], join=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JycVNUb618eZ",
        "outputId": "5a460493-70e3-427e-ff0b-b7373a987094"
      },
      "outputs": [],
      "source": [
        "# Identificar registros duplicados\n",
        "duplicated_north = north_soil_data[north_soil_data.index.duplicated(keep=False)]\n",
        "duplicated_south = south_soil_data[south_soil_data.index.duplicated(keep=False)]\n",
        "\n",
        "# print(duplicated_north)\n",
        "# print(duplicated_south)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para rellenar con NaNs los saltos temporales del df\n",
        "\n",
        "def reindex_dataframes(date_filtered_df, interval):\n",
        "\n",
        "    # Generar un índice a intervalo regular del periodo completo\n",
        "    full_index = pd.date_range(\n",
        "        start=date_filtered_df.index.min(),\n",
        "        end=date_filtered_df.index.max(),\n",
        "        freq=interval,\n",
        "        name=date_filtered_df.index.name\n",
        "    )\n",
        "\n",
        "    # Reindexar el date_filtered_df usando el full index\n",
        "    reindexed_df = date_filtered_df.reindex(full_index)\n",
        "\n",
        "    return reindexed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar dfs por periodo de funcionamiento de cada intervalo de medicion\n",
        "\n",
        "# Sitio norte\n",
        "north_15min = north_soil_data.loc[north_soil_data.index.min():'2024-10-17 14:30:00']\n",
        "north_10min = north_soil_data.loc['2024-10-17 14:30:01':north_soil_data.index.max()]\n",
        "\n",
        "# Sitio sur\n",
        "south_15min = south_soil_data.loc[south_soil_data.index.min():'2024-10-17 23:00:00']\n",
        "south_10min = south_soil_data.loc['2024-10-17 23:00:01':south_soil_data.index.max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ejecutar función de reindexación\n",
        "\n",
        "# Sitio norte\n",
        "north_15min_reindexed = reindex_dataframes(north_15min, '15min')\n",
        "north_10min_reindexed = reindex_dataframes(north_10min, '10min') \n",
        "\n",
        "# Sitio sur\n",
        "south_15min_reindexed = reindex_dataframes(south_15min, '15min')\n",
        "south_10min_reindexed = reindex_dataframes(south_10min, '10min')    # 2024-10-17 23:10 no se crea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oikU8Q1pNMQp"
      },
      "outputs": [],
      "source": [
        "# Concatenar los dataframes para re-unificarlos\n",
        "north_soil_data = pd.concat([north_15min_reindexed, north_10min_reindexed])\n",
        "south_soil_data = pd.concat([south_15min_reindexed, south_10min_reindexed])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportar datos procesados como csv\n",
        "\n",
        "north_soil_data.to_csv('../../data/processed/cleaned/soil_SDH1_cleaned.csv')\n",
        "south_soil_data.to_csv('../../data/processed/cleaned/soil_SDH2_cleaned.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
